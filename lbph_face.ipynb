{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np # importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier(r'D:\\Others\\Projects\\LBPH\\haarcascade_frontalface_default.xml')\n",
    "# creating a face detector\n",
    "recognizer=cv2.face.LBPHFaceRecognizer_create() # generating face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_images(User): # defining function to capture and store face images\n",
    "    if not os.path.exists('Faces'):\n",
    "        os.makedirs('Faces') # creating a new dictionary for save captured images\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    \n",
    "    count=0\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) # converting to gray frame\n",
    "        faces=face_cascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30)) # detecting faces in gray frame\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.imwrite(f'Faces/{User}_{count}.jpg',gray[y:y+h,x:x+w]) # store the captures images in the created folder\n",
    "            count=count+1\n",
    "        cv2.imshow('capture face',frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "        if count>=400:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_images('Athiresh') # creating data sets of user faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_images('Hailee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_images('Neymar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_images('Yadhu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture_images('New user') to add more user faces datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Athiresh': 0, 'Hailee': 1, 'Neymar': 2, 'Yadhu': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label={'Athiresh':0,'Hailee':1,'Neymar':2,'Yadhu':3} # creating a dictionary of respective usernames to encode into the numerical vector\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.face.LBPHFaceRecognizer 000001C033907D30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(label): # defining function to train model\n",
    "    faces=[]\n",
    "    labels=[] # creating lists to store the face samples and their corresponding labels\n",
    "\n",
    "    for file_name in os.listdir('Faces'):\n",
    "        name=file_name.split('_')[0] # extracting the username from file name\n",
    "\n",
    "        image=cv2.imread(os.path.join('Faces',file_name))\n",
    "        gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        detected_faces=face_cascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30))\n",
    "\n",
    "        if len(detected_faces)>0: # cheching if face is detected and cropping the face region\n",
    "\n",
    "            face_crop=gray[detected_faces[0][1]:detected_faces[0][1]+detected_faces[0][3],\n",
    "                           detected_faces[0][0]:detected_faces[0][0]+detected_faces[0][2]]\n",
    "            faces.append(face_crop)\n",
    "            labels.append(label[name]) # faces and labels list appending\n",
    "\n",
    "    recognizer=cv2.face.LBPHFaceRecognizer_create() # training the face recognition model using the faces and labels\n",
    "    recognizer.train(faces,np.array(labels))\n",
    "    return recognizer\n",
    "\n",
    "Recognizer=train_model(label)\n",
    "Recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(recognizer,label): # function to recognize faces\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    label_name={value:key for key, value in label.items()}\n",
    "    while True:\n",
    "        ret,frame=cap.read()\n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_cascade.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30))\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "\n",
    "            label,confidence=recognizer.predict(gray[y:y+h, x:x+w]) # recognize the face using trained model\n",
    "            if confidence>90:\n",
    "                cv2.putText(frame,'Unknown',(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2) # frame with unknown face\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            \n",
    "            else:\n",
    "                cv2.putText(frame,label_name[label],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2) # frame with face and label name\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "        cv2.imshow('recognize_faces',frame)\n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_faces(Recognizer,label) # real time recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
